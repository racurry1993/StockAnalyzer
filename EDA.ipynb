{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5959e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7dcadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'd3piSzhjYWxhdHRKNFpnU1Azakc6MTpjaQ'\n",
    "client_id_secret = 'iTyHTvVdyGmR-232UBk1RswW0s1SFPW8aQflF1-3PFptF-OJbh'\n",
    "api_secret = 'OggcdFdwI3U8iag9IbEgqc9TPk3tIzD8dTgTJi7C2zfUmWOXFw'\n",
    "api_key = 'BpcTsRKW0jnflmCvCrjk6EcNt'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABzx3gEAAAAAFal9LhOHENKlwO%2FqBZ0E1shIUtg%3DDdSjaV1zqYTFdC3DfBm8i1eIG8nDz5BL2B4WnjqO9cPI197pzQ'\n",
    "access_token = '934895513090101250-wPIZaSff0C1ulOrPOIDSv7UHK0s73R5'\n",
    "access_token_secret = 'AbVdhq1oo5ooKyPttSL5hI8VrSkHVU4P3aBy8uVBeNmL0'\n",
    "# X API setup (replace with your credentials)\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Stock list\n",
    "stocks = ['AAPL', 'TSLA', 'MSFT', 'RIVN']\n",
    "\n",
    "# Number of lags for features\n",
    "LAGS = [1, 2, 3, 7]\n",
    "\n",
    "# Prediction horizon (days)\n",
    "HORIZON = 30\n",
    "\n",
    "# Confidence thresholds for neural network\n",
    "BUY_THRESHOLD = 0.7\n",
    "SELL_THRESHOLD = 0.3\n",
    "\n",
    "# Function to fetch sentiment from X\n",
    "def get_sentiment(stock):\n",
    "    query = f\"${stock} -from:stockbot\"\n",
    "    tweets = api.search_tweets(q=query, count=100, lang=\"en\", tweet_mode=\"extended\")\n",
    "    sentiments = []\n",
    "    for tweet in tweets:\n",
    "        try:\n",
    "            text = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            text = tweet.full_text\n",
    "        analysis = TextBlob(text)\n",
    "        sentiments.append(analysis.sentiment.polarity)\n",
    "    return np.mean(sentiments) if sentiments else 0.0\n",
    "\n",
    "# Function to fetch stock data, technical indicators, lagging features, and temporal features\n",
    "def get_stock_data(stock, start_date, end_date):\n",
    "    df = yf.download(stock, start=start_date, end=end_date)\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    # Long-term trend target: 1 if price increases over next 30 days, 0 otherwise\n",
    "    df['Future_Close'] = df['Close'].shift(-HORIZON)\n",
    "    df['Target'] = (df['Future_Close'] > df['Close']).astype(int)\n",
    "    #df['Sentiment'] = get_sentiment(stock)\n",
    "    # Technical indicators\n",
    "    df['RSI'] = RSIIndicator(df['Close']).rsi()\n",
    "    macd = MACD(df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_Signal'] = macd.macd_signal()\n",
    "    # Lagging features\n",
    "    features_to_lag = ['Close', 'Volume', 'RSI', 'MACD', 'MACD_Signal']#, 'Sentiment']\n",
    "    for feature in features_to_lag:\n",
    "        for lag in LAGS:\n",
    "            df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "    # Day-of-week and month features\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['Day_of_Week'] = df.index.dayofweek + 1  # Monday=1, ..., Sunday=7\n",
    "    df['Month'] = df.index.month  # January=1, ..., December=12\n",
    "    return df.dropna()\n",
    "\n",
    "# Function to prepare data for ML\n",
    "def prepare_data(df):\n",
    "    features = ['Close', 'Volume', 'RSI', 'MACD', 'MACD_Signal', 'Day_of_Week', 'Month']#, 'Sentiment']\n",
    "    for feature in ['Close', 'Volume', 'RSI', 'MACD', 'MACD_Signal']:#, 'Sentiment']:\n",
    "        for lag in LAGS:\n",
    "            features.append(f'{feature}_lag_{lag}')\n",
    "    X = df[features]\n",
    "    y = df['Target']\n",
    "    return X, y\n",
    "\n",
    "# Neural Network model\n",
    "def build_neural_network(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Neural Network\n",
    "    nn_model = build_neural_network(X_train.shape[1])\n",
    "    history = nn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    nn_pred = (nn_model.predict(X_test) > 0.5).astype(int)\n",
    "    nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "    \n",
    "    # Random Forest with GridSearchCV\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_params = {'n_estimators': [50, 100], 'max_depth': [None, 10]}\n",
    "    rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    rf_pred = rf_grid.predict(X_test)\n",
    "    rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "    \n",
    "    # SVM with GridSearchCV\n",
    "    svm = SVC(random_state=42, probability=True)  # Enable probabilities for SVM\n",
    "    svm_params = {'C': [0.1, 1], 'kernel': ['linear', 'rbf']}\n",
    "    svm_grid = GridSearchCV(svm, svm_params, cv=5)\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    svm_pred = svm_grid.predict(X_test)\n",
    "    svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "    \n",
    "    return {\n",
    "        'nn': {'model': nn_model, 'accuracy': nn_accuracy, 'history': history},\n",
    "        'rf': {'model': rf_grid, 'accuracy': rf_accuracy},\n",
    "        'svm': {'model': svm_grid, 'accuracy': svm_accuracy}\n",
    "    }\n",
    "\n",
    "# Generate buy/sell signals with confidence threshold\n",
    "def generate_signals(df, model, model_type):\n",
    "    X, _ = prepare_data(df)\n",
    "    if model_type == 'nn':\n",
    "        probabilities = model.predict(X)\n",
    "        signals = np.where(probabilities > BUY_THRESHOLD, 'Buy',\n",
    "                          np.where(probabilities < SELL_THRESHOLD, 'Sell', 'Hold')).flatten()\n",
    "    else:\n",
    "        probabilities = model.predict_proba(X)[:, 1]  # Probability of class 1 (uptrend)\n",
    "        signals = np.where(probabilities > BUY_THRESHOLD, 'Buy',\n",
    "                          np.where(probabilities < SELL_THRESHOLD, 'Sell', 'Hold')).flatten()\n",
    "    df['Signal'] = signals\n",
    "    return df\n",
    "\n",
    "# Calculate gains/losses over the prediction horizon\n",
    "def calculate_gains(df):\n",
    "    df['Position'] = df['Signal'].shift(1)  # Shift to avoid look-ahead bias\n",
    "    # Calculate return over the horizon period after a Buy signal\n",
    "    df['Horizon_Return'] = (df['Future_Close'] - df['Close']) / df['Close']\n",
    "    df['Trade_Return'] = df['Horizon_Return'] * (df['Position'] == 'Buy').astype(int)\n",
    "    df['Cumulative_Gain'] = (1 + df['Trade_Return']).cumprod() - 1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8ada434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'AAPL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    }
   ],
   "source": [
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365 + HORIZON)\n",
    "df = yf.download('AAPL', start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf6b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'AAPL' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m get_stock_data(stock, start_date, end_date)\n\u001b[0;32m      7\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m prepare_data(df)\n\u001b[1;32m----> 8\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     results[stock] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m: df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m: models}\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[10], line 86\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_models\u001b[39m(X, y):\n\u001b[1;32m---> 86\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# Neural Network\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     nn_model \u001b[38;5;241m=\u001b[39m build_neural_network(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\rfo7799\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rfo7799\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rfo7799\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365 + HORIZON)\n",
    "results = {}\n",
    "for stock in stocks:\n",
    "    df = get_stock_data(stock, start_date, end_date)\n",
    "    X, y = prepare_data(df)\n",
    "    models = train_models(X, y)\n",
    "    results[stock] = {'df': df, 'models': models}\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fee56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Dashboard\n",
    "def main():\n",
    "    st.title(\"Stock Trend Prediction Dashboard (30-Day Horizon)\")\n",
    "    \n",
    "    st.write(\"Signals predict whether the stock will trend upward or downward over the next 30 days. \"\n",
    "             \"'Buy' indicates an expected uptrend, 'Sell' a downtrend, and 'Hold' low confidence.\")\n",
    "    \n",
    "    # Fetch data\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365 + HORIZON)\n",
    "    results = {}\n",
    "    for stock in stocks:\n",
    "        df = get_stock_data(stock, start_date, end_date)\n",
    "        X, y = prepare_data(df)\n",
    "        models = train_models(X, y)\n",
    "        results[stock] = {'df': df, 'models': models}\n",
    "    \n",
    "    # Bar chart of accuracies\n",
    "    accuracies = []\n",
    "    for stock in stocks:\n",
    "        for model_name, model_info in results[stock]['models'].items():\n",
    "            accuracies.append({'Stock': stock, 'Model': model_name, 'Accuracy': model_info['accuracy']})\n",
    "    acc_df = pd.DataFrame(accuracies)\n",
    "    acc_df = acc_df.sort_values('Accuracy', ascending=False)\n",
    "    \n",
    "    st.subheader(\"Model Accuracy by Stock\")\n",
    "    fig = px.bar(acc_df, x='Stock', y='Accuracy', color='Model', barmode='group')\n",
    "    st.plotly_chart(fig)\n",
    "    \n",
    "    # Stock and model selection\n",
    "    selected_stock = st.selectbox(\"Select Stock\", stocks)\n",
    "    selected_model = st.selectbox(\"Select Model\", ['nn', 'rf', 'svm'])\n",
    "    \n",
    "    df = results[selected_stock]['df']\n",
    "    model_info = results[selected_stock]['models'][selected_model]\n",
    "    model = model_info['model']\n",
    "    \n",
    "    # Generate signals and calculate gains\n",
    "    df_signals = generate_signals(df, model, selected_model)\n",
    "    df_signals = calculate_gains(df_signals)\n",
    "    \n",
    "    # Buy/Sell/Hold signals plot\n",
    "    st.subheader(f\"Buy/Sell/Hold Signals for {selected_stock} (30-Day Trend)\")\n",
    "    fig_signals = go.Figure()\n",
    "    fig_signals.add_trace(go.Scatter(x=df_signals.index, y=df_signals['Close'], name='Close Price'))\n",
    "    buy_signals = df_signals[df_signals['Signal'] == 'Buy']\n",
    "    sell_signals = df_signals[df_signals['Signal'] == 'Sell']\n",
    "    hold_signals = df_signals[df_signals['Signal'] == 'Hold']\n",
    "    fig_signals.add_trace(go.Scatter(x=buy_signals.index, y=buy_signals['Close'], mode='markers', \n",
    "                                    name='Buy', marker=dict(symbol='triangle-up', size=10, color='green')))\n",
    "    fig_signals.add_trace(go.Scatter(x=sell_signals.index, y=sell_signals['Close'], mode='markers', \n",
    "                                    name='Sell', marker=dict(symbol='triangle-down', size=10, color='red')))\n",
    "    fig_signals.add_trace(go.Scatter(x=hold_signals.index, y=hold_signals['Close'], mode='markers', \n",
    "                                    name='Hold', marker=dict(symbol='circle', size=8, color='gray')))\n",
    "    st.plotly_chart(fig_signals)\n",
    "    \n",
    "    # Cumulative gains\n",
    "    st.subheader(\"Cumulative Gains (30-Day Holding Periods)\")\n",
    "    st.write(f\"Total Gain/Loss: {df_signals['Cumulative_Gain'].iloc[-1]:.2%}\")\n",
    "    fig_gains = px.line(df_signals, x=df_signals.index, y='Cumulative_Gain', title='Cumulative Returns')\n",
    "    st.plotly_chart(fig_gains)\n",
    "    \n",
    "    # Sentiment analysis chart\n",
    "    st.subheader(\"Sentiment Analysis\")\n",
    "    sentiment = df['Sentiment'].iloc[-1]\n",
    "    st.write(f\"Latest Sentiment Score: {sentiment:.2f} (Positive > 0, Negative < 0)\")\n",
    "    fig_sentiment = px.line(df, x=df.index, y='Sentiment', title='Sentiment Trend')\n",
    "    st.plotly_chart(fig_sentiment)\n",
    "    \n",
    "    # Backpropagation trend (for neural network)\n",
    "    if selected_model == 'nn':\n",
    "        st.subheader(\"Neural Network Backpropagation Trend\")\n",
    "        history = model_info['history']\n",
    "        fig_loss = go.Figure()\n",
    "        fig_loss.add_trace(go.Scatter(y=history.history['loss'], name='Training Loss'))\n",
    "        fig_loss.add_trace(go.Scatter(y=history.history['val_loss'], name='Validation Loss'))\n",
    "        fig_loss.update_layout(title='Neural Network Loss Over Epochs', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "        st.plotly_chart(fig_loss)\n",
    "    \n",
    "    # Technical indicators\n",
    "    st.subheader(\"Technical Indicators\")\n",
    "    fig_tech = go.Figure()\n",
    "    fig_tech.add_trace(go.Scatter(x=df.index, y=df['RSI'], name='RSI'))\n",
    "    fig_tech.add_trace(go.Scatter(x=df.index, y=df['MACD'], name='MACD'))\n",
    "    fig_tech.add_trace(go.Scatter(x=df.index, y=df['MACD_Signal'], name='MACD Signal'))\n",
    "    st.plotly_chart(fig_tech)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
